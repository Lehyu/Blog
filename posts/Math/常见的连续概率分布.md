## 高斯分布

高斯分布是统计学与机器学习中使用最广泛的分布，他的概率密度函数( $pdf$ )：

$$\begin{equation}
\begin{array}{rcl}
\mathcal{N}(x\vert\mu,\sigma^{2}) = \frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}
\end{array}
\end{equation}$$

高斯分布的精度：$\lambda = 1/\sigma^{2}$，精度越高意味着高斯分布越集中在 $\mu$ 附近。

累计分布函数：$\Phi(x;\mu, \sigma^{2})=\int_{-\infty}^{x}\mathcal{N}(z\vert\mu,\sigma^{2})\,dz$

$$$\Phi(x;\mu, \sigma^{2})=\frac{1}{2}[1+erf(z/\sqrt{2})]$$$
其中 $z = (x-\mu)/\sigma$，$erf(x)=\frac{2}{\sqrt{\pi}}\int_0^{x}e^{-t^{2}}dt$

## 退化分布

当 $\sigma^{2} \to 0$ 时，高斯分布就集中在 $\mu$ 上：
$\lim_{\sigma^{2} \to 0} \mathcal{N}(x\vert \mu,\sigma^{2})=\delta(x-u)$
其中 $\delta$ 是 狄拉克 $\delta$ 函数

$$\begin{equation}
\begin{array}{rcl}
\delta(x)=\cases{\infty & if x = 0 \cr 0 & if otherwise}
\end{array}
\end{equation}$$

Student t 分布

$$\begin{equation}
\begin{array}{rcl}
\mathcal{T}(x\vert\mu,\sigma^{2},\nu) \propto [1+\frac{1}{\nu}(\frac{x-\mu}{\sigma})^{2}]^{-(\frac{\nu+1}{2})}
\end{array}
\end{equation}$$


## 拉普拉斯分布

$$\begin{equation}
\begin{array}{rcl}
Lap(x\vert\mu,b)=\frac{1}{2b}exp(-\frac{\|x-\mu\|}{b})
\end{array}
\end{equation}$$

其中 $mean = \mu, mode=\mu,var=2b^{2}$，拉普拉斯分布对离散点比高斯分布更鲁棒。并且在很多点上的概率密度都为0，因此可以用来稀疏化一个模型。

![alt gtl](https://raw.githubusercontent.com/Lehyu/lehyu.cn/master/image/math/probability%20distribution/gtl.png)

![alt gtl_outlier](https://raw.githubusercontent.com/Lehyu/lehyu.cn/master/image/math/probability%20distribution/gtl_outlier.png)

## 伽马分布

伽马分布是一个对正实数随机变量很灵活的分布，$Ga(T\vert shape=a, rate=b)=\frac{b^{a}}{\Gamma(a)}T^{a-1}e^{-Tb}$， $a>0,b>0$

其中，$\Gamma(x)=\int_{0}^{\infty}\mu^{x-1}e^{-\mu}d\mu$

并且 $mean=\frac{a}{b},mode=\frac{a-1}{b},var=\frac{a}{b^{2}}$

伽马的逆：$IG(x\vert shape=a,scale=b)=\frac{b^{a}}{\Gamma(a)}T^{-(a+1)}e^{-b/x}$

如果 $X\thicksim Ga(a,b)$， 则 $\frac{1}{X} \thicksim IG(a,b)$

而且该分布：$mean=\frac{b}{a-1},mode=\frac{b}{a+1},var=\frac{b^{2}}{(a-1)^2(a-2)}$

### 集中特殊情况下的伽马分布

1. 指数分布：$Exp(x\vert \lambda)=Ga(x\vert 1,\lambda)$
2. Erlang分布：$Erlang(x\vert \lambda)=Ga(x\vert 2,\lambda)$
3. Chi-squared分布：$\chi^{2}(x\vert \nu)=Ga(x\vert \frac{\nu}{2},\frac{1}{2})$。如果$Z_i\thicksim\mathcal{N}(0,1),S=\sum_{i=1}^{\nu}Z_{i}^{2}$，那么 $S\thicksim\chi_{\nu}^{2}$

## 贝塔分布

贝塔分布在[0,1]内，$Beta(x\vert a,b)=\frac{1}{B(a,b)}x^{a-1}(1-x)^{b-1}$，其中 $B(a,b)=\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}$

![alt beta](https://raw.githubusercontent.com/Lehyu/lehyu.cn/master/image/math/probability%20distribution/beta.png)

$$\begin{equation}
\begin{array}{rcl}
mean = \frac{a}{a+b},mode=\frac{a-1}{a+b-2},var=\frac{ab}{(a+b)^2(a+b+1)}
\end{array}
\end{equation}$$

## 狄利克雷分布(Dirichlet Distribution)

$S_K=\{x:0 \leq x_k \leq 1,\sum_{k=1}^K x_k =1\}$, 概率密度函数函数：

$$\begin{equation}
\begin{array}{rcl}
Dir(x\vert \alpha)=\frac{1}{B(\alpha)} \prod_{k=1}^K x_{k}^{\alpha_k-1}\mathbb{I}(x \in S_K)
\end{array}
\end{equation}$$

其中$B(\alpha)=\frac{\prod_{k=1}^{K}\Gamma(\alpha_k)}{ \Gamma(\alpha_0) }$

## 帕累托分布

80/20法则: $Pareto(x\vert k,m)=km^kx^{-(k+1)}\mathbb{1}(x\geq m)$

$$\begin{equation}
\begin{array}{rcl}
mean=\frac{km}{k-1},mode=m,var=\frac{m^2 k}{(k-1)^2(k-2)}
\end{array}
\end{equation}$$


![alt Pareto](https://raw.githubusercontent.com/Lehyu/lehyu.cn/master/image/math/probability%20distribution/pareto.png)

## 参考

Machine Learning A Probabilistic Perspective
[帕累托分布](http://wiki.mbalib.com/wiki/%E5%B8%95%E7%B4%AF%E6%89%98%E5%88%86%E5%B8%83)
